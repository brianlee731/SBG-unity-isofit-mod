{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9451aa7d-0d18-4d8d-bda1-e91d60d30985",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# SBG ISOFIT Application Notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1251c9f4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-01 20:41:22.320274: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-01 20:41:23.182506: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-02-01 20:41:23.182544: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-02-01 20:41:25.171640: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-02-01 20:41:25.171975: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-02-01 20:41:25.172055: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "from spectral.io import envi\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import hytools_lite as ht\n",
    "from isofit.utils import surface_model\n",
    "import time\n",
    "\n",
    "\n",
    "# stage_in packages\n",
    "from unity_sds_client.resources.collection import Collection\n",
    "\n",
    "# stage_out packages\n",
    "from datetime import datetime, timezone\n",
    "from unity_sds_client.resources.dataset import Dataset\n",
    "from unity_sds_client.resources.data_file import DataFile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19ed576-cb3b-4428-b18c-ddc456ceead7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Inputs and Configurations\n",
    "\n",
    "In the original pre-process, inputs are supplied by a run_config file. This consists of 2 entries (a raw_data file, and a CRID). The system in reality needs 3 inputs files (an observation file, a radiance file, and the crid configurable.\n",
    "\n",
    "In the Unity system, the data files required will be staged in for the applicaiton, and the crid is a config item that is passed in. To make this work in Unity, we will also pass in an \"output collection\" which is needed if we want to \"persist\" the output products in the data catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a07e7e7-2ddf-46ac-9efd-000f86da7476",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# The defaults used here generally relflect a local or jupyter environment; they are replaced with \"runtime\" values when run in the system.\n",
    "input_stac_collection_file = '/unity/ads/input_collections/SBG-L1B-PRE/subset/catalog.json' # type: stage-in\n",
    "output_stac_catalog_dir    = '/unity/ads/outputs/SBG-L2A-RFL/process_results'                    # type: stage-out\n",
    "\n",
    "# pre-process variables\n",
    "output_collection=\"SBG-L2A-RFL\"\n",
    "crid = \"001\"\n",
    "cores=1\n",
    "segmentation_size=10\n",
    "tmp_work = '/unity/ads/temp/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d59430e1-d900-4541-8b8b-e5c38e3ee8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_work = tmp_work.rstrip(\"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b7fa38",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Import Files from STAC Item Collection\n",
    "\n",
    "Load filenames from the stage_in STAC item collection file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a09d57c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/unity/ads/input_collections/SBG-L1B-PRE/subset/./SISTER_EMIT_L1B_RDN_20231206T160939_001.bin',\n",
       " '/unity/ads/input_collections/SBG-L1B-PRE/subset/./.SISTER_EMIT_L1B_RDN_20231206T160939_001.json']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_collection = Collection.from_stac(input_stac_collection_file)\n",
    "data_filenames = inp_collection.data_locations()\n",
    "\n",
    "data_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf78b9d-a058-4f41-81e3-c1360ee764c2",
   "metadata": {},
   "source": [
    "## Misc. function required by the preprocess command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee32bc59-4ed6-426c-929f-ff17835b95e5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_rfl_basename(rdn_basename, crid):\n",
    "    # Replace product type\n",
    "    tmp_basename = rdn_basename.replace(\"L1B_RDN\", \"L2A_RFL\")\n",
    "    # Split, remove old CRID, and add new one\n",
    "    tokens = tmp_basename.split(\"_\")[:-1] + [str(crid)]\n",
    "    return \"_\".join(tokens)\n",
    "\n",
    "\n",
    "def generate_wavelengths(rdn_hdr_path, output_path):\n",
    "    # Read in header file and get list of wavelengths and fwhm\n",
    "    hdr = envi.read_envi_header(rdn_hdr_path)\n",
    "    wl = hdr[\"wavelength\"]\n",
    "    fwhm = hdr[\"fwhm\"]\n",
    "\n",
    "    # Need to offset fwhm if its length is not the same as the wavelengths' length.  This is a known bug in\n",
    "    # the AVIRIS-NG data.\n",
    "    fwhm_offset = 0 if len(wl) == len(fwhm) else 23\n",
    "    wl_arr = []\n",
    "    for i in range(len(wl)):\n",
    "        wl_arr.append([i, wl[i], fwhm[i + fwhm_offset]])\n",
    "\n",
    "    # Save file\n",
    "    np.savetxt(output_path, np.array(wl_arr, dtype=np.float32))\n",
    "\n",
    "\n",
    "def generate_metadata(run_config,json_path,new_metadata):\n",
    "\n",
    "    metadata= run_config['metadata']\n",
    "    for key,value in new_metadata.items():\n",
    "        metadata[key] = value\n",
    "\n",
    "    with open(json_path, 'w') as out_obj:\n",
    "        json.dump(metadata,out_obj,indent=3)\n",
    "\n",
    "def generate_quicklook(rfl_img_path, output_path):\n",
    "    # Generate a quicklook browse image\n",
    "    img = ht.HyTools()\n",
    "    img.read_file(rfl_img_path)\n",
    "\n",
    "    if 'DESIS' in img.base_name:\n",
    "        band3 = img.get_wave(560)\n",
    "        band2 = img.get_wave(850)\n",
    "        band1 = img.get_wave(660)\n",
    "    else:\n",
    "        band3 = img.get_wave(560)\n",
    "        band2 = img.get_wave(850)\n",
    "        band1 = img.get_wave(1660)\n",
    "\n",
    "    rgb = np.stack([band1, band2, band3])\n",
    "    rgb[rgb == img.no_data] = np.nan\n",
    "\n",
    "    rgb = np.moveaxis(rgb,0,-1).astype(float)\n",
    "    bottom = np.nanpercentile(rgb, 5, axis=(0, 1))\n",
    "    top = np.nanpercentile(rgb, 95, axis=(0, 1))\n",
    "    rgb = np.clip(rgb, bottom, top)\n",
    "    rgb = (rgb - np.nanmin(rgb, axis=(0, 1))) / (np.nanmax(rgb, axis=(0, 1)) - np.nanmin(rgb, axis=(0, 1)))\n",
    "    rgb = (rgb * 255).astype(np.uint8)\n",
    "\n",
    "    im = Image.fromarray(rgb)\n",
    "    im.save(output_path)\n",
    "\n",
    "def update_header_descriptions(hdr_path, description):\n",
    "    hdr = envi.read_envi_header(hdr_path)\n",
    "    hdr[\"description\"] = description\n",
    "    envi.write_envi_header(hdr_path, hdr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8993a54b-7b15-49a0-ab10-e6d611aa2e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/SBG/SBG-unity-isofit/isofit'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Define paths and variables\n",
    "sister_isofit_dir = globals()['_dh'][0]\n",
    "isofit_dir = os.path.join(os.path.dirname(sister_isofit_dir),sister_isofit_dir.name ,\"isofit\")\n",
    "isofit_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ddc7216-1199-4ca2-a392-7daea56a24d1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUTS: /unity/ads/input_collections/SBG-L1B-PRE/subset/.\n",
      "RAD: SISTER_EMIT_L1B_RDN_20231206T160939_001\n",
      "OBS: SISTER_EMIT_L1B_RDN_20231206T160939_001_OBS\n",
      "LOC: SISTER_EMIT_L1B_RDN_20231206T160939_001_LOC\n",
      "RFL: SISTER_EMIT_L2A_RFL_20231206T160939_001\n",
      "TEMP BASENAME: emit20231206T160939\n"
     ]
    }
   ],
   "source": [
    "for f in data_filenames:\n",
    "    if f.endswith(\".bin\"):\n",
    "      if \"_OBS\" in f:\n",
    "        continue\n",
    "      elif \"_LOC\" in f:\n",
    "        continue\n",
    "      else:\n",
    "        input_dir = os.path.dirname(f)\n",
    "        rdn_name_wbin = os.path.basename(f)\n",
    "        rdn_basename = rdn_name_wbin[:-4]\n",
    "\n",
    "rfl_basename = get_rfl_basename(rdn_basename, crid)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "loc_basename = f\"{rdn_basename}_LOC\"\n",
    "obs_basename = f\"{rdn_basename}_OBS\"\n",
    "print(\"INPUTS: \" + input_dir)\n",
    "print(\"RAD: \" + rdn_basename)\n",
    "print(\"OBS: \" + obs_basename)\n",
    "print(\"LOC: \" + loc_basename )\n",
    "print(\"RFL: \" + rfl_basename )\n",
    "\n",
    "instrument = \"EMIT\"\n",
    "sensor = 'emit'\n",
    "\n",
    "temp_basename = f'{sensor}{os.path.basename(rdn_basename).split(\"_\")[4]}'\n",
    "surface_config = tmp_work+\"/emit_surface_20221020.json\"\n",
    "\n",
    "print(\"TEMP BASENAME: \" + temp_basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25b000ad-0742-49ec-acbe-1d1c114c20a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/unity/ads/temp/emit20231206T160939_OBS.hdr'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Temporary input filenames without .bin extension\n",
    "    \n",
    "rdn_img_path = f\"{tmp_work}/{temp_basename}\"\n",
    "rdn_hdr_path = f\"{tmp_work}/{temp_basename}.hdr\"\n",
    "loc_img_path = f\"{tmp_work}/{temp_basename}_LOC\"\n",
    "loc_hdr_path = f\"{tmp_work}/{temp_basename}_LOC.hdr\"\n",
    "obs_img_path = f\"{tmp_work}/{temp_basename}_OBS\"\n",
    "obs_hdr_path = f\"{tmp_work}/{temp_basename}_OBS.hdr\"\n",
    "\n",
    "# Copy the input files into the work directory (don't use .bin)\n",
    "shutil.copyfile(f\"{input_dir}/{rdn_basename}.bin\" ,rdn_img_path)\n",
    "shutil.copyfile(f\"{input_dir}/{rdn_basename}.hdr\" ,rdn_hdr_path)\n",
    "shutil.copyfile(f\"{input_dir}/{loc_basename}.bin\" ,loc_img_path)\n",
    "shutil.copyfile(f\"{input_dir}/{loc_basename}.hdr\" ,loc_hdr_path)\n",
    "shutil.copyfile(f\"{input_dir}/{obs_basename}.bin\" ,obs_img_path)\n",
    "shutil.copyfile(f\"{input_dir}/{obs_basename}.hdr\" ,obs_hdr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfa0a72e-4700-4331-9d3a-8531eebd3dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating wavelengths from radiance header path at /unity/ads/temp/emit20231206T160939.hdr to /unity/ads/temp/wavelengths.txt\n"
     ]
    }
   ],
   "source": [
    "#Update radiance basename\n",
    "rdn_basename = os.path.basename(rdn_img_path)\n",
    "\n",
    "# Generate wavelengths file\n",
    "wavelengths_path = tmp_work + \"/wavelengths.txt\"\n",
    "print(f\"Generating wavelengths from radiance header path at {rdn_hdr_path} to {wavelengths_path}\")\n",
    "generate_wavelengths(rdn_hdr_path, wavelengths_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7185db4-a5d9-418a-bf6e-37e058deeaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating surface model using work/surface.json config\n",
      "0 ['filtered_other']\n",
      "1 ['filtered_other']\n",
      "2 ['filtered_other']\n",
      "3 ['filtered_other']\n",
      "4 ['filtered_other']\n",
      "0 ['filtered_veg']\n",
      "0 ['filtered_ocean']\n",
      "0 ['surface_Liquids']\n",
      "1 ['surface_Liquids']\n"
     ]
    }
   ],
   "source": [
    "# Copy surface model files to input folder and generate surface model\n",
    "print(\"Generating surface model using work/surface.json config\")\n",
    "subprocess.run(f\"cp {sister_isofit_dir}/surface_model/* {tmp_work}/\", shell=True)\n",
    "surface_model_path = tmp_work+\"/surface.mat\"\n",
    "surface_model(surface_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a55086a-4294-4a02-ae09-f53a59a0557b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/SBG/SBG-unity-isofit/6s\n"
     ]
    }
   ],
   "source": [
    "os.environ['SIXS_DIR'] = str(sister_isofit_dir) + \"/6s\"\n",
    "print(str(sister_isofit_dir) + \"/6s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdc8df7f-c0af-42fb-8226-dd1182376943",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_oe_exe = f\"{sister_isofit_dir}/isofit/isofit/utils/apply_oe.py\"\n",
    "log_basename = f\"{rfl_basename}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03cd2076-aac9-44a3-8408-c0800dd61d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running apply_oe command: python /home/jovyan/SBG/SBG-unity-isofit/isofit/isofit/utils/apply_oe.py /unity/ads/temp/emit20231206T160939 /unity/ads/temp/emit20231206T160939_LOC /unity/ads/temp/emit20231206T160939_OBS work emit --presolve=1 --analytical_line=0 --empirical_line=1 --emulator_base=/home/jovyan/SBG/SBG-unity-isofit/sRTMnet_v120.h5 --n_cores=1 --wavelength_path=/unity/ads/temp/wavelengths.txt --surface_path=/unity/ads/temp/surface.mat --segmentation_size=10 --log_file=/unity/ads/temp/SISTER_EMIT_L2A_RFL_20231206T160939_001.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-01 20:42:18.555258: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-01 20:42:18.737883: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-02-01 20:42:18.737922: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-02-01 20:42:19.485571: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-02-01 20:42:19.485676: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-02-01 20:42:19.485685: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/opt/conda/envs/sister/lib/python3.8/site-packages/osgeo/gdal.py:312: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/sister/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/envs/sister/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/SBG/SBG-unity-isofit/isofit/isofit/utils/apply_oe.py\", line 1533, in <module>\n",
      "    main()\n",
      "  File \"/home/jovyan/SBG/SBG-unity-isofit/isofit/isofit/utils/apply_oe.py\", line 205, in main\n",
      "    to_sensor_azimuth_lut_grid, to_sensor_zenith_lut_grid = get_metadata_from_obs(paths.obs_working_path, lut_params)\n",
      "  File \"/home/jovyan/SBG/SBG-unity-isofit/isofit/isofit/utils/apply_oe.py\", line 1004, in get_metadata_from_obs\n",
      "    mean_to_sensor_azimuth = lut_params.get_angular_grid(to_sensor_azimuth[valid], -1, 0) % 360\n",
      "  File \"/home/jovyan/SBG/SBG-unity-isofit/isofit/isofit/utils/apply_oe.py\", line 790, in get_angular_grid\n",
      "    gmm.fit(spatial_data)\n",
      "  File \"/opt/conda/envs/sister/lib/python3.8/site-packages/sklearn/mixture/_base.py\", line 181, in fit\n",
      "    self.fit_predict(X, y)\n",
      "  File \"/opt/conda/envs/sister/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/conda/envs/sister/lib/python3.8/site-packages/sklearn/mixture/_base.py\", line 212, in fit_predict\n",
      "    X = self._validate_data(X, dtype=[np.float64, np.float32], ensure_min_samples=2)\n",
      "  File \"/opt/conda/envs/sister/lib/python3.8/site-packages/sklearn/base.py\", line 605, in _validate_data\n",
      "    out = check_array(X, input_name=\"X\", **check_params)\n",
      "  File \"/opt/conda/envs/sister/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 967, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with 0 sample(s) (shape=(0, 2)) while a minimum of 2 is required by GaussianMixture.\n"
     ]
    }
   ],
   "source": [
    "cmd = [\n",
    "    \"python\",\n",
    "    apply_oe_exe,\n",
    "    rdn_img_path,\n",
    "    loc_img_path,\n",
    "    obs_img_path,\n",
    "    \"work\",\n",
    "    sensor,\n",
    "    \"--presolve=1\",\n",
    "    \"--analytical_line=0\",\n",
    "    \"--empirical_line=1\",\n",
    "    \"--emulator_base=\"+str(sister_isofit_dir)+\"/sRTMnet_v120.h5\",\n",
    "    f\"--n_cores={cores}\",\n",
    "    f\"--wavelength_path={wavelengths_path}\",\n",
    "    f\"--surface_path={surface_model_path}\",\n",
    "    f\"--segmentation_size={segmentation_size}\",\n",
    "    f\"--log_file={tmp_work}/{log_basename}\"\n",
    "]\n",
    "\n",
    "print(\"Running apply_oe command: \" + \" \".join(cmd))\n",
    "\n",
    "start_time = time.time()\n",
    "subprocess.run(\" \".join(cmd), shell=True)\n",
    "end_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf66e035-4fd0-4531-a9a7-d3a75f573516",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check to see if output/temp directories exist:\n",
    "# This is really onl required if running through the notebook; want to make sure we've got the locations setup\n",
    "# for temp and output creation.\n",
    "pathlib.Path(output_stac_catalog_dir).mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(temp_directory).mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89224c4e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Create stage-out item catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aa5d3b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# stage_in packages\n",
    "from unity_sds_client.resources.collection import Collection\n",
    "\n",
    "# stage_out packages\n",
    "from datetime import datetime, timezone\n",
    "from unity_sds_client.resources.dataset import Dataset\n",
    "from unity_sds_client.resources.data_file import DataFile\n",
    "\n",
    "# Create a collection\n",
    "out_collection = Collection(\"L1B_preprocessed\")\n",
    "\n",
    "data_files = glob.glob(output_stac_catalog_dir+\"/SISTER*RDN*.bin\") \n",
    "# hack to get the radiance file\n",
    "data_file = os.path.basename(data_files[0].replace(\"_LOC\",\"\").replace(\"_OBS\",\"\"))\n",
    "name=os.path.splitext(data_file)[0]\n",
    "\n",
    "# Get some metadata from met.json file\n",
    "with open(output_stac_catalog_dir + \"/\" + name+\".met.json\") as metadata:\n",
    "    md_dict = json.load(metadata)\n",
    "    start_time = md_dict['start_time']\n",
    "    end_time = md_dict['end_time']\n",
    "\n",
    "# Create a Dataset for the collection\n",
    "dataset = Dataset(\n",
    "    name=name, \n",
    "    collection_id=out_collection.collection_id, \n",
    "    start_time=start_time, \n",
    "    end_time=end_time,\n",
    "    creation_time=datetime.utcnow().replace(tzinfo=timezone.utc).isoformat(),\n",
    ")\n",
    "\n",
    "# Add output file(s) to the dataset\n",
    "for file in glob.glob(output_stac_catalog_dir+\"/SISTER*\"):\n",
    "    key = 'data'\n",
    "    dataset.add_data_file(DataFile(key, file))\n",
    "\n",
    "# the future metadata file needs to be added to the STAC as well\n",
    "    # will eventually be moved into the to_stac() function\n",
    "dataset.add_data_file(DataFile(\"metadata\", output_stac_catalog_dir + name +'.json' ))\n",
    "\n",
    "\n",
    "# Add the dataset to the collection\n",
    "#out_collection.add_dataset(dataset)\n",
    "out_collection._datasets.append(dataset)\n",
    "\n",
    "Collection.to_stac(out_collection, output_stac_catalog_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8147a197-398c-4358-a5cf-cd8b7a6a0ef6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python [conda env:sister]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
